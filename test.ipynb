{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m567.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 KB\u001b[0m \u001b[31m396.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[541 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /usr/lib/python3.9/site-packages/setuptools/dist.py:723: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/worker.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/version.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/util.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/traceback_utils.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/taskcontext.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/storagelevel.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/status.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/statcounter.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/shuffle.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/shell.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/serializers.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resultiterable.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/rddsampler.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/rdd.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/profiler.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/join.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/java_gateway.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/install.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/find_spark_home.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/files.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/daemon.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/context.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/conf.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/broadcast.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/accumulators.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/_globals.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/__init__.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/compat.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/cloudpickle_fast.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/cloudpickle.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/__init__.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/util.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/tree.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/regression.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/recommendation.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/random.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/fpm.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/feature.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/evaluation.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/common.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/clustering.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/classification.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/__init__.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/distributed.py -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/__init__.py -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/test.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/distribution.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/_statistics.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/__init__.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/KernelDensity.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/wrapper.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/util.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tuning.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tree.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/stat.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/regression.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/recommendation.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/pipeline.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/image.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/functions.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/fpm.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/feature.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/evaluation.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/common.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/clustering.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/classification.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/base.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/__init__.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/ml/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/linalg/__init__.py -> build/lib/pyspark/ml/linalg\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/shared.py -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/_shared_params_code_gen.py -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/__init__.py -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/window.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/utils.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/udf.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/types.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/streaming.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/session.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/readwriter.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/group.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/functions.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/dataframe.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/context.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/conf.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/column.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/catalog.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/__init__.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/avro/functions.py -> build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/avro/__init__.py -> build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/utils.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/types.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/typehints.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/serializers.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/map_ops.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/group_ops.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/functions.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/conversion.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/__init__.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/util.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/listener.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/kinesis.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/dstream.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/context.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/__init__.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/bin/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/sbin/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/jars/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/window.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/utils.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/strings.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/sql_processor.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/series.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/numpy_compat.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/namespace.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/mlflow.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/ml.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/internal.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexing.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/groupby.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/generic.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/frame.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/extensions.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/exceptions.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/datetimes.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/config.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/categorical.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/base.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/accessors.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/_typing.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/__init__.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/udt_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/string_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/num_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/null_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/datetime_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/date_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/complex_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/categorical_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/boolean_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/binary_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/base.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/__init__.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/numeric.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/multi.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/datetimes.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/category.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/base.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/__init__.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/window.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/series.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/indexes.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/groupby.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/frame.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/common.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/__init__.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/plotly.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/matplotlib.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/core.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/__init__.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/utils.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/functions.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/accessors.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/__init__.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/typedef/typehints.py -> build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/typedef/string_typehints.py -> build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/typedef/__init__.py -> build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/usage_logging\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/usage_logging/usage_logger.py -> build/lib/pyspark/pandas/usage_logging\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/usage_logging/__init__.py -> build/lib/pyspark/pandas/usage_logging\n",
      "  \u001b[31m   \u001b[0m package init file 'pyspark/python/pyspark/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/python\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/python/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/python/pyspark/shell.py -> build/lib/pyspark/python/pyspark\n",
      "  \u001b[31m   \u001b[0m package init file 'lib/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/data/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/licenses/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/requests.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/profile.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/information.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/__init__.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/examples/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples/src\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples/src/main\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/wordcount.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/transitive_closure.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/status_api_demo.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/sort.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/pi.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/parquet_inputformat.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/pagerank.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/logistic_regression.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/kmeans.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/avro_inputformat.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/als.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pyspark.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pyspark.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to pyspark.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pyspark.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pyspark.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.py[cod]' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pyspark.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying pyspark/__init__.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/_typing.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/accumulators.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/broadcast.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/conf.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/context.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/files.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/profiler.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/py.typed -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/rdd.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resultiterable.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/statcounter.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/status.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/storagelevel.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/taskcontext.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/util.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/version.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/_typing.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/classification.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/clustering.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/common.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/evaluation.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/feature.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/fpm.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/random.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/recommendation.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/regression.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/tree.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/util.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/__init__.pyi -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/distributed.pyi -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/KernelDensity.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/__init__.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/_statistics.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/distribution.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/test.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/_typing.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/base.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/classification.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/clustering.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/common.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/evaluation.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/feature.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/fpm.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/functions.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/image.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/pipeline.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/recommendation.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/regression.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/stat.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tree.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tuning.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/util.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/wrapper.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/linalg/__init__.pyi -> build/lib/pyspark/ml/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/__init__.pyi -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/_shared_params_code_gen.pyi -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/shared.pyi -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/__init__.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/_typing.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/catalog.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/column.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/conf.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/context.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/dataframe.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/functions.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/group.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/readwriter.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/session.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/streaming.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/types.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/udf.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/window.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/avro/functions.pyi -> build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/conversion.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/functions.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/group_ops.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/map_ops.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/pandas/_typing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/__init__.pyi -> build/lib/pyspark/sql/pandas/_typing\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/protocols/__init__.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/protocols/frame.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/protocols/series.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/context.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/dstream.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/kinesis.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/listener.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/beeline -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/beeline.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/docker-image-tool.sh -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/find-spark-home -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/find-spark-home.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/load-spark-env.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/load-spark-env.sh -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/pyspark -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/pyspark.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/pyspark2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/run-example -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/run-example.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-class -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-class.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-class2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-shell -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-shell.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-shell2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-sql -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-sql.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-sql2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-submit -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-submit.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-submit2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/sparkR -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/sparkR.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/sparkR2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/spark-config.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/spark-daemon.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/start-history-server.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/stop-history-server.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/HikariCP-2.5.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/JLargeArrays-1.5.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/JTransforms-3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/RoaringBitmap-0.9.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/ST4-4.0.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/activation-1.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/aircompressor-0.21.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/algebra_2.12-2.0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/annotations-17.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/antlr-runtime-3.5.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/antlr4-runtime-4.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/aopalliance-repackaged-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arpack-2.2.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arpack_combined_all-0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-format-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-memory-core-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-memory-netty-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-vector-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/audience-annotations-0.5.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/automaton-1.11-8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/avro-1.10.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/avro-ipc-1.10.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/avro-mapred-1.10.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/blas-2.2.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/bonecp-0.8.0.RELEASE.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/breeze-macros_2.12-1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/breeze_2.12-1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/cats-kernel_2.12-2.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/chill-java-0.10.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/chill_2.12-0.10.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-cli-1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-codec-1.15.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-collections-3.2.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-compiler-3.0.16.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-compress-1.21.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-crypto-1.1.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-dbcp-1.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-io-2.8.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-lang-2.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-lang3-3.12.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-logging-1.1.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-math3-3.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-net-3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-pool-1.5.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-text-1.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/compress-lzf-1.0.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/core-1.1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/curator-client-2.13.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/curator-framework-2.13.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/curator-recipes-2.13.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/datanucleus-api-jdo-4.2.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/datanucleus-core-4.1.17.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/datanucleus-rdbms-4.1.19.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/derby-10.14.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/flatbuffers-java-1.9.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/generex-1.0.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/gson-2.2.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/guava-14.0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-client-api-3.3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-client-runtime-3.3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-shaded-guava-1.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-yarn-server-web-proxy-3.3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-beeline-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-cli-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-common-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-exec-2.3.9-core.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-jdbc-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-llap-common-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-metastore-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-serde-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-service-rpc-3.1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-0.23-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-common-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-scheduler-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-storage-api-2.7.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-vector-code-gen-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hk2-api-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hk2-locator-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hk2-utils-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/htrace-core4-4.1.0-incubating.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/httpclient-4.5.13.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/httpcore-4.4.14.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/istack-commons-runtime-3.0.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/ivy-2.5.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-annotations-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-core-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-core-asl-1.9.13.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-databind-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-dataformat-yaml-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-datatype-jsr310-2.11.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-mapper-asl-1.9.13.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-module-scala_2.12-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.annotation-api-1.3.5.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.inject-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.servlet-api-4.0.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.validation-api-2.0.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.ws.rs-api-2.1.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.xml.bind-api-2.3.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/janino-3.0.16.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/javassist-3.25.0-GA.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/javax.jdo-3.2.0-m3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/javolution-5.5.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jaxb-api-2.2.11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jaxb-runtime-2.3.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jcl-over-slf4j-1.7.30.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jdo-api-3.0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-client-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-common-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-container-servlet-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-container-servlet-core-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-hk2-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-server-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jline-2.14.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/joda-time-2.10.10.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jodd-core-3.5.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jpam-1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json-1.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-ast_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-core_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-jackson_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-scalap_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jsr305-3.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jta-1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jul-to-slf4j-1.7.30.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kryo-shaded-4.0.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-client-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-admissionregistration-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-apiextensions-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-apps-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-autoscaling-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-batch-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-certificates-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-common-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-coordination-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-core-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-discovery-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-events-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-extensions-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-flowcontrol-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-metrics-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-networking-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-node-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-policy-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-rbac-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-scheduling-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-storageclass-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/lapack-2.2.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/leveldbjni-all-1.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/libfb303-0.9.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/libthrift-0.12.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/log4j-1.2.17.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/logging-interceptor-3.12.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/lz4-java-1.7.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/macro-compat_2.12-1.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/mesos-1.4.0-shaded-protobuf.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-core-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-graphite-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-jmx-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-json-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-jvm-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/minlog-1.3.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/netty-all-4.1.68.Final.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/objenesis-2.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/okhttp-3.12.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/okio-1.14.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/opencsv-2.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/orc-core-1.6.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/orc-mapreduce-1.6.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/orc-shims-1.6.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/oro-2.0.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/osgi-resource-locator-1.0.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/paranamer-2.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-column-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-common-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-encoding-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-format-structures-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-hadoop-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-jackson-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/protobuf-java-2.5.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/py4j-0.10.9.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/pyrolite-4.30.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/rocksdbjni-6.20.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m error: [Errno 28] No space left on device\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pyspark\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pyspark\n",
      "Failed to build pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Running setup.py install for pyspark ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for pyspark\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[543 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /usr/lib/python3.9/site-packages/setuptools/dist.py:723: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /usr/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/worker.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/version.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/util.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/traceback_utils.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/taskcontext.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/storagelevel.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/status.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/statcounter.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/shuffle.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/shell.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/serializers.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resultiterable.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/rddsampler.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/rdd.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/profiler.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/join.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/java_gateway.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/install.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/find_spark_home.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/files.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/daemon.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/context.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/conf.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/broadcast.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/accumulators.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/_globals.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/__init__.py -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/compat.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/cloudpickle_fast.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/cloudpickle.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m copying pyspark/cloudpickle/__init__.py -> build/lib/pyspark/cloudpickle\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/util.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/tree.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/regression.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/recommendation.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/random.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/fpm.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/feature.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/evaluation.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/common.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/clustering.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/classification.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/__init__.py -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/distributed.py -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/__init__.py -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/test.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/distribution.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/_statistics.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/__init__.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/KernelDensity.py -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/wrapper.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/util.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tuning.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tree.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/stat.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/regression.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/recommendation.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/pipeline.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/image.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/functions.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/fpm.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/feature.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/evaluation.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/common.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/clustering.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/classification.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/base.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/__init__.py -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/ml/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/linalg/__init__.py -> build/lib/pyspark/ml/linalg\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/shared.py -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/_shared_params_code_gen.py -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/__init__.py -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/window.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/utils.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/udf.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/types.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/streaming.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/session.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/readwriter.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/group.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/functions.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/dataframe.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/context.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/conf.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/column.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/catalog.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/__init__.py -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/avro/functions.py -> build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/avro/__init__.py -> build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/utils.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/types.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/typehints.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/serializers.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/map_ops.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/group_ops.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/functions.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/conversion.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/__init__.py -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/util.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/listener.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/kinesis.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/dstream.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/context.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/__init__.py -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/bin/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/sbin/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/jars/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/window.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/utils.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/strings.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/sql_processor.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/series.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/numpy_compat.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/namespace.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/mlflow.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/ml.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/internal.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexing.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/groupby.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/generic.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/frame.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/extensions.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/exceptions.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/datetimes.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/config.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/categorical.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/base.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/accessors.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/_typing.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/__init__.py -> build/lib/pyspark/pandas\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/udt_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/string_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/num_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/null_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/datetime_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/date_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/complex_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/categorical_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/boolean_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/binary_ops.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/base.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/data_type_ops/__init__.py -> build/lib/pyspark/pandas/data_type_ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/numeric.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/multi.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/datetimes.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/category.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/base.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/indexes/__init__.py -> build/lib/pyspark/pandas/indexes\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/window.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/series.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/indexes.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/groupby.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/frame.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/common.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/missing/__init__.py -> build/lib/pyspark/pandas/missing\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/plotly.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/matplotlib.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/core.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/plot/__init__.py -> build/lib/pyspark/pandas/plot\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/utils.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/functions.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/accessors.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/spark/__init__.py -> build/lib/pyspark/pandas/spark\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/typedef/typehints.py -> build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/typedef/string_typehints.py -> build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/typedef/__init__.py -> build/lib/pyspark/pandas/typedef\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/pandas/usage_logging\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/usage_logging/usage_logger.py -> build/lib/pyspark/pandas/usage_logging\n",
      "  \u001b[31m   \u001b[0m copying pyspark/pandas/usage_logging/__init__.py -> build/lib/pyspark/pandas/usage_logging\n",
      "  \u001b[31m   \u001b[0m package init file 'pyspark/python/pyspark/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/python\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/python/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/python/pyspark/shell.py -> build/lib/pyspark/python/pyspark\n",
      "  \u001b[31m   \u001b[0m package init file 'lib/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/data/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/licenses/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/requests.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/profile.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/information.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resource/__init__.py -> build/lib/pyspark/resource\n",
      "  \u001b[31m   \u001b[0m package init file 'deps/examples/__init__.py' not found (or not a regular file)\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples/src\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples/src/main\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/wordcount.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/transitive_closure.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/status_api_demo.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/sort.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/pi.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/parquet_inputformat.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/pagerank.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/logistic_regression.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/kmeans.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/avro_inputformat.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m copying deps/examples/als.py -> build/lib/pyspark/examples/src/main/python\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pyspark.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pyspark.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to pyspark.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pyspark.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pyspark.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.py[cod]' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pyspark.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying pyspark/__init__.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/_typing.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/accumulators.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/broadcast.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/conf.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/context.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/files.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/profiler.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/py.typed -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/rdd.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/resultiterable.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/statcounter.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/status.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/storagelevel.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/taskcontext.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/util.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/version.pyi -> build/lib/pyspark\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/_typing.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/classification.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/clustering.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/common.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/evaluation.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/feature.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/fpm.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/random.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/recommendation.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/regression.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/tree.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/util.pyi -> build/lib/pyspark/mllib\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/__init__.pyi -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/linalg/distributed.pyi -> build/lib/pyspark/mllib/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/KernelDensity.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/__init__.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/_statistics.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/distribution.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/mllib/stat/test.pyi -> build/lib/pyspark/mllib/stat\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/_typing.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/base.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/classification.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/clustering.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/common.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/evaluation.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/feature.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/fpm.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/functions.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/image.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/pipeline.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/recommendation.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/regression.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/stat.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tree.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/tuning.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/util.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/wrapper.pyi -> build/lib/pyspark/ml\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/linalg/__init__.pyi -> build/lib/pyspark/ml/linalg\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/__init__.pyi -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/_shared_params_code_gen.pyi -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/ml/param/shared.pyi -> build/lib/pyspark/ml/param\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/__init__.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/_typing.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/catalog.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/column.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/conf.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/context.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/dataframe.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/functions.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/group.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/readwriter.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/session.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/streaming.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/types.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/udf.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/window.pyi -> build/lib/pyspark/sql\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/avro/functions.pyi -> build/lib/pyspark/sql/avro\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/conversion.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/functions.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/group_ops.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/map_ops.pyi -> build/lib/pyspark/sql/pandas\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/pandas/_typing\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/__init__.pyi -> build/lib/pyspark/sql/pandas/_typing\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/protocols/__init__.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/protocols/frame.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/sql/pandas/_typing/protocols/series.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/context.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/dstream.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/kinesis.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m copying pyspark/streaming/listener.pyi -> build/lib/pyspark/streaming\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/beeline -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/beeline.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/docker-image-tool.sh -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/find-spark-home -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/find-spark-home.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/load-spark-env.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/load-spark-env.sh -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/pyspark -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/pyspark.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/pyspark2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/run-example -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/run-example.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-class -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-class.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-class2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-shell -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-shell.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-shell2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-sql -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-sql.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-sql2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-submit -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-submit.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/spark-submit2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/sparkR -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/sparkR.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m copying deps/bin/sparkR2.cmd -> build/lib/pyspark/bin\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/spark-config.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/spark-daemon.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/start-history-server.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m copying deps/sbin/stop-history-server.sh -> build/lib/pyspark/sbin\n",
      "  \u001b[31m   \u001b[0m creating build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/HikariCP-2.5.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/JLargeArrays-1.5.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/JTransforms-3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/RoaringBitmap-0.9.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/ST4-4.0.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/activation-1.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/aircompressor-0.21.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/algebra_2.12-2.0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/annotations-17.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/antlr-runtime-3.5.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/antlr4-runtime-4.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/aopalliance-repackaged-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arpack-2.2.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arpack_combined_all-0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-format-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-memory-core-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-memory-netty-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/arrow-vector-2.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/audience-annotations-0.5.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/automaton-1.11-8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/avro-1.10.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/avro-ipc-1.10.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/avro-mapred-1.10.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/blas-2.2.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/bonecp-0.8.0.RELEASE.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/breeze-macros_2.12-1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/breeze_2.12-1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/cats-kernel_2.12-2.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/chill-java-0.10.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/chill_2.12-0.10.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-cli-1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-codec-1.15.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-collections-3.2.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-compiler-3.0.16.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-compress-1.21.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-crypto-1.1.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-dbcp-1.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-io-2.8.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-lang-2.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-lang3-3.12.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-logging-1.1.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-math3-3.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-net-3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-pool-1.5.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/commons-text-1.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/compress-lzf-1.0.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/core-1.1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/curator-client-2.13.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/curator-framework-2.13.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/curator-recipes-2.13.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/datanucleus-api-jdo-4.2.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/datanucleus-core-4.1.17.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/datanucleus-rdbms-4.1.19.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/derby-10.14.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/flatbuffers-java-1.9.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/generex-1.0.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/gson-2.2.4.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/guava-14.0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-client-api-3.3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-client-runtime-3.3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-shaded-guava-1.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hadoop-yarn-server-web-proxy-3.3.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-beeline-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-cli-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-common-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-exec-2.3.9-core.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-jdbc-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-llap-common-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-metastore-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-serde-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-service-rpc-3.1.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-0.23-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-common-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-shims-scheduler-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-storage-api-2.7.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hive-vector-code-gen-2.3.9.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hk2-api-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hk2-locator-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/hk2-utils-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/htrace-core4-4.1.0-incubating.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/httpclient-4.5.13.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/httpcore-4.4.14.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/istack-commons-runtime-3.0.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/ivy-2.5.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-annotations-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-core-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-core-asl-1.9.13.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-databind-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-dataformat-yaml-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-datatype-jsr310-2.11.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-mapper-asl-1.9.13.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jackson-module-scala_2.12-2.12.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.annotation-api-1.3.5.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.inject-2.6.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.servlet-api-4.0.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.validation-api-2.0.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.ws.rs-api-2.1.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jakarta.xml.bind-api-2.3.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/janino-3.0.16.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/javassist-3.25.0-GA.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/javax.jdo-3.2.0-m3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/javolution-5.5.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jaxb-api-2.2.11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jaxb-runtime-2.3.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jcl-over-slf4j-1.7.30.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jdo-api-3.0.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-client-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-common-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-container-servlet-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-container-servlet-core-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-hk2-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jersey-server-2.34.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jline-2.14.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/joda-time-2.10.10.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jodd-core-3.5.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jpam-1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json-1.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-ast_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-core_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-jackson_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/json4s-scalap_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jsr305-3.0.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jta-1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/jul-to-slf4j-1.7.30.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kryo-shaded-4.0.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-client-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-admissionregistration-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-apiextensions-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-apps-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-autoscaling-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-batch-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-certificates-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-common-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-coordination-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-core-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-discovery-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-events-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-extensions-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-flowcontrol-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-metrics-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-networking-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-node-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-policy-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-rbac-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-scheduling-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/kubernetes-model-storageclass-5.4.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/lapack-2.2.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/leveldbjni-all-1.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/libfb303-0.9.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/libthrift-0.12.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/log4j-1.2.17.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/logging-interceptor-3.12.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/lz4-java-1.7.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/macro-compat_2.12-1.1.1.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/mesos-1.4.0-shaded-protobuf.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-core-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-graphite-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-jmx-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-json-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/metrics-jvm-4.2.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/minlog-1.3.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/netty-all-4.1.68.Final.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/objenesis-2.6.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/okhttp-3.12.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/okio-1.14.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/opencsv-2.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/orc-core-1.6.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/orc-mapreduce-1.6.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/orc-shims-1.6.12.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/oro-2.0.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/osgi-resource-locator-1.0.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/paranamer-2.8.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-column-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-common-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-encoding-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-format-structures-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-hadoop-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/parquet-jackson-1.12.2.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/protobuf-java-2.5.0.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/py4j-0.10.9.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/pyrolite-4.30.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m copying deps/jars/rocksdbjni-6.20.3.jar -> build/lib/pyspark/jars\n",
      "  \u001b[31m   \u001b[0m error: [Errno 28] No space left on device\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m pyspark\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder().master(\"local[1]\")\n",
    "          .appName(\"SparkByExamples.com\")\n",
    "          .getOrCreate()\n",
    "df = spark.read.csv(\"/tmp/resources/zipcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1398102, 1), indices imply (1398102, 1398102)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000001?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000001?line=19'>20</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(finput, dtype\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m, skiprows\u001b[39m=\u001b[39mi, max_rows \u001b[39m=\u001b[39m row_loops, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000001?line=20'>21</a>\u001b[0m df_new \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data, columns\u001b[39m=\u001b[39;49mcolnames)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000001?line=21'>22</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mappend(df_new\u001b[39m.\u001b[39mastype(column_types), ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brenoslivio/Documents/IC/kmers_evaluation/test.ipynb#ch0000001?line=23'>24</a>\u001b[0m \u001b[39mdel\u001b[39;00m df_new\n",
      "File \u001b[0;32m/var/data/python/lib/python3.9/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=683'>684</a>\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=684'>685</a>\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=685'>686</a>\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=690'>691</a>\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=691'>692</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=692'>693</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=693'>694</a>\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=694'>695</a>\u001b[0m             data,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=695'>696</a>\u001b[0m             index,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=696'>697</a>\u001b[0m             columns,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=697'>698</a>\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=698'>699</a>\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=699'>700</a>\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=700'>701</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=702'>703</a>\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/frame.py?line=703'>704</a>\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=345'>346</a>\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=346'>347</a>\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=347'>348</a>\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=348'>349</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=350'>351</a>\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=352'>353</a>\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=354'>355</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=419'>420</a>\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=420'>421</a>\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> <a href='file:///var/data/python/lib/python3.9/site-packages/pandas/core/internals/construction.py?line=421'>422</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1398102, 1), indices imply (1398102, 1398102)"
     ]
    }
   ],
   "source": [
    "finput = 'D1/kmers.csv'\n",
    "\n",
    "colnames = np.loadtxt(finput, dtype=str, max_rows = 1, delimiter=',')\n",
    "types = []\n",
    "types.append(str)\n",
    "\n",
    "for i in range(len(colnames) - 2):\n",
    "    types.append(np.float32)\n",
    "\n",
    "types.append(str)\n",
    "column_types = dict(zip(colnames, types))\n",
    "\n",
    "n_lines = sum(1 for row in open(finput))\n",
    "\n",
    "df = pd.DataFrame(columns=colnames)\n",
    "\n",
    "row_loops = 1\n",
    "for i in range(1, 3, row_loops): # read 500 lines at a time\n",
    "    print(i)\n",
    "    data = np.loadtxt(finput, dtype=str, skiprows=i, max_rows = row_loops, delimiter=',')\n",
    "    df_new = pd.DataFrame(data, columns=colnames)\n",
    "    df = df.append(df_new.astype(column_types), ignore_index=True)\n",
    "\n",
    "    del df_new\n",
    "    del data\n",
    "\n",
    "df = df[~df.nameseq.str.contains(\"nameseq\")]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
